{"cells":[{"cell_type":"markdown","metadata":{"id":"he2yaW2PPt1G"},"source":["# Presentación de la empresa, organización o problema específico  \n","\n","#### De acuerdo a la Organización Mundial de la Salud (OMS), ACV es la segunda causa de muerte a nivel global, responsable de aproximadamente 11% de las muertes totales.\n","#### Este set de datos es utilizado para predecir si un paciente es propenso a tener un ACV basado en los parametros como género, edad, enfermedades varias, y estado de fumador. Cada fila en los datos provee información relevante sobre el paciente.\n"]},{"cell_type":"markdown","metadata":{"id":"8--juv6d-8yL"},"source":["#### Preguntas y objetivos de la investigación.\n","\n",".¿Cuál es el género más propenso a tener un acv?  \n",".¿Cuál es el grado de influencia de ser fumador?  \n",".¿Existe relación entre el índice de masa corporal y el nivel de glucosa para contraer un acv?  \n",".¿Qué tanto influye el tipo de trabajo en la posibilidad de tener un acv?  \n",".¿Aumentan las probabilidades de tener un acv a mayor edad?    \n",".¿Tener hipertensión influye a la hora de tener un acv?  // Se cambió la pregunta en base a la corrección de Maxi, no tenemos niveles de hipertensión, sólo veradero o falso\n",".¿Tiene relación el estado marital con tener un acv?  \n","\n","\n","El objetivo de la investigación es determinar cuales son las variables mas influyentes a la hora de provocar un acv. Utilizando un modelo de predicción vamos a poder determinar si una persona es mas propensa a tener un acv.\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"FlJG0RbG_mW3"},"source":["#### 3. Conformación del equipo de trabajo. \n","Martin Marino  \n","Leandro Bruzzo  "]},{"cell_type":"markdown","metadata":{"id":"v0Or7A6f_GjS"},"source":["# Indicación de la fuente del dataset y los criterios de selección (Data Acquisition)\n","#### El dataset fue obtenido de la plataforma Kaggle desde el siguiente link : https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset\n","\n","#### Información sobre el data set:\n","- Creador: fedesoriano - https://www.kaggle.com/fedesoriano\n","\n","- Información de los atributos: \n","1) id: identificador único  \n","2) gender: \"Male\", \"Female\" o \"Other\" (Masculino, Femenino u Otro)  \n","3) age: Edad del paciente  \n","4) hypertension: 0 si el paciente no tiene hipertensión , 1 si el paciente tiene hipertensión  \n","5) heart_disease: 0 si el paciente no tiene enfermedades del corazón, 1 si el paciente tiene enfermedades del corazón  \n","6) ever_married: \"No\" o \"Yes\" (No o Sí)  \n","7) work_type: \"children\", \"Govt_jov\", \"Never_worked\", \"Private\" or \"Self-employed\" (Niño, trabajo en el sector público, nunca trabajó, privado o monotributista)  \n","8) Residence_type: \"Rural\" or \"Urban\"   \n","9) avg_glucose_level: nivel promedio de glucosa en la sangre  \n","10) bmi: Índice de masa corporal  \n","11) smoking_status: \"formerly smoked\", \"never smoked\", \"smokes\" or \"Unknown\"* (Fumador frecuente, nunca fumó, fuma, desconocido)  \n","12) stroke: 1 si el paciente tuvo un ACV 0 si no lo tuvo (Variable Target)  \n","*Nota: 'Uknown' en smoking_status indica que no se registró un estado del paciente.\n","\n","Información sobre Kaggle:\n","Kaggle, una subsidiaria de Google LLC, es una comunidad en línea de científicos de datos y profesionales del aprendizaje automático."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Librerías neceasrias para el correcto funcionamiento del jupyter (descomentar para ejecutar por primera vez y luego volver a comentarlo)\n","\n","# import sys\n","# !{sys.executable} -m pip install --upgrade pip\n","# !{sys.executable} -m pip install pandas\n","# !{sys.executable} -m pip install numpy\n","# !{sys.executable} -m pip install seaborn\n","# !{sys.executable} -m pip install matplotlib\n","# !{sys.executable} -m pip install pandas_profiling\n","# !{sys.executable} -m pip install plotly.express\n","# !{sys.executable} -m pip install ipywidgets\n","# !{sys.executable} -m pip install nbformat\n","# !{sys.executable} -m pip install sklearn"]},{"cell_type":"markdown","metadata":{},"source":["#### Importamos todas las librerias de visualización, modelos de ML y validación"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LOeWHwPvPt1c"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import pandas_profiling\n","import plotly.express as px\n","\n","from sklearn.model_selection import train_test_split \n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.linear_model import LogisticRegression\n","\n","from sklearn.metrics import balanced_accuracy_score\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import roc_auc_score, auc\n","from sklearn.metrics import roc_curve\n","\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import plot_confusion_matrix\n","\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.datasets import make_classification\n","from sklearn.metrics import classification_report"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yvxe9FmLPt1e","outputId":"9f8476e3-dcf7-4fa2-c159-0a83c63212ee"},"outputs":[],"source":["df = pd.read_csv('healthcare-dataset-stroke-data.csv')\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0reaKW_dPt1h","outputId":"0c73f07a-ac4d-4d0c-99c9-3b7ef17130c1"},"outputs":[],"source":["df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Creamos un dataframe con las columnas work_type y residence_type en booleano (Es decir, 0 y 1) para ser utilizados en la matriz de correlación\n","\n","df.rename(columns = {'Residence_type':'residence_type'}, inplace = True)\n","df_2 = df #Realizamos una copia del dataframe original para la matriz de correlación\n","#Reemplazamos los valores Yes y No de ever_married con 1 y 0\n","df_2['ever_married'].replace(\n","                to_replace=['Yes', 'No'], \n","                value=[1,0,], \n","                inplace=True, \n",")\n","df_2['residence_type'].replace(\n","                to_replace=['Urban', 'Rural'], \n","                value=[0,1,], \n","                inplace=True, \n",")\n","\n","df_2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fn1_PqBePt1j","outputId":"6ce2a757-795c-48ef-cc73-c927a7d3eb2b"},"outputs":[],"source":["df_2.describe().T"]},{"cell_type":"markdown","metadata":{"id":"rCGKYOU-Pt1k"},"source":["#### EDA Utilizando la librería pandas_profiling"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qhHw_6UtPt1l","outputId":"2426eeb2-602c-43c9-a228-3f7ed0cf6ab7","scrolled":true},"outputs":[],"source":["df_2.profile_report(title='Data Profiling')"]},{"cell_type":"markdown","metadata":{},"source":["#### Con el siguiente gráfico de torta podemos observar el gran desbalanceo de nuestro set de datos. Esto será crucial a la hora de preparar nuestros algoritmos, ya que un desbalance tan marcado puede ocasionar una gran pérdida de precisión y será necesario el uso de técnicas específicas para tratar dicho desbalanceo.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8xI2Xqb8Pt1q","outputId":"c1611d50-f9b9-4838-b84b-8ff4fe9fd3a2"},"outputs":[],"source":["df_pie = df.copy()\n","df_pie['stroke'].replace(\n","                to_replace=[0, 1], \n","                value=[\"No\",\"Yes\"], \n","                inplace=True)\n","fig = px.pie(df_pie, names=\"stroke\",values='id', hole=.35, title='Stroke Distribution')\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.stroke.value_counts()"]},{"cell_type":"markdown","metadata":{},"source":["#### Filtros y limpieza del dataset a utilizar para los modelos de ML"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"unYzhZLkPt1x","outputId":"437e79b9-8fdd-40c5-cd56-ace21eb41181"},"outputs":[],"source":["#Vemos los valores unicos para la columna de smoking status y posteriormente excluimos los desconocidos\n","df['smoking_status'].unique()"]},{"cell_type":"markdown","metadata":{},"source":["#### En smoking_status se puede observar que tenemos valores \"Unknown\", se realizará un conteo de los mismos para observar el impacto de su eliminación, ya que dicho estado no nos aporta nada en el análisis."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q1TpaAeAPt1y","outputId":"61be3e77-cf27-4550-a547-0db52592169e"},"outputs":[],"source":["df.smoking_status.value_counts()"]},{"cell_type":"markdown","metadata":{},"source":["#### Unknown tiene una cantidad de registros de 1544, aproximadamente el 30% de los datos. Debido a que no podemos asumir si esa persona fuma o no, se tomará la decisión de eliminarlos. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Eliminar los datos unknown de la columna smoking_status\n","\n","df['smoking_status'].values\n","df = df[df.smoking_status != 'Unknown']\n","df.smoking_status.value_counts()"]},{"cell_type":"markdown","metadata":{},"source":["#### BMI tiene 140 valores nulos, los mismos podrían ser eliminados pero debido a que el dataset perdió gran cantidad de datos al eliminar los registros con smoking_status = Unknown, se precederá a utilizar un promedio para los mismos.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for i in df.columns[df.isnull().any(axis=0)]:   \n","    df[i].fillna(df[i].mean(),inplace=True)\n","df.info()"]},{"cell_type":"markdown","metadata":{},"source":["#### Como se pudo observar en la línea anterior, se han completados los valores NaN de la columna BMI con el valor promedio de los mismos"]},{"cell_type":"markdown","metadata":{},"source":["#### En la columna gender podemos observar que hay un único registro con el género other, por motivos de espacio de memoria el mismo será eliminado ya que al preparar el dataset para utilizar algoritmos de clasificación empleando data dummies, se creará una columna extra en consecuencia de este único valor."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.gender.value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = df[df.gender != 'Other']\n","df.gender.value_counts()"]},{"cell_type":"markdown","metadata":{},"source":["#### Hay que tener en consideración la pérdida de datos, hemos pasado de 5110 registros a 3566. Sin embargo, estos datos siguen siendo válidos, más limpios y pueden ser utilizados para el modelo de ML. "]},{"cell_type":"markdown","metadata":{},"source":["#### Llegado a este punto, el data set pasa a estar a un estado mucho más útil, limpio y con mayor facilidad para su manipulación.  \n","#### Comenzaremos con el EDA para obtener respuestas, patrones y entender mejor los datos"]},{"cell_type":"markdown","metadata":{},"source":["#### Emplearemos el uso de un mapa de correlación"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CT4su8exPt1s","outputId":"0bb0f77f-0fa6-4c39-fdf0-805176a4c97e"},"outputs":[],"source":["#Creamos un df sin la columna id para ser utizado en el mapa de correlación, ya que el mismo es un identificador único.\n","dfHeatmap = df.drop(columns=['id'])\n","plt.figure(dpi = 120,figsize= (6,6))\n","mask = np.triu(np.ones_like(dfHeatmap.corr(),dtype = bool))\n","sns.heatmap(dfHeatmap.corr(),mask = mask, fmt = \".2f\",annot=True,lw=1,cmap = 'plasma', vmax=1, vmin=0)\n","plt.yticks(rotation = 0)\n","plt.xticks(rotation = 90)\n","plt.title('Correlation Heatmap')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["\n","Se ha decidido descartar la columna residence_type, ya que esta no presenta un impacto en el dataset ni correlaciones positivas y/o negativas de forma significante. (-0,02 como el mayor coeficiente)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Eliminamos la columna residence_type antes de seguir analizando en profundida el dataset.\n","df.drop(['residence_type'], axis=1, inplace=True)\n","df.info()"]},{"cell_type":"markdown","metadata":{},"source":["Se ha decidido eliminar la columna ever_married, ya que si bien es la variable más correlacionada con age, esta sólo nos demuestra que a mayor edad, la gente es más propensa a estar casada. Este dato no nos aporta valor para el objetivo al que queremos llegar. Además, se han hecho pruebas con los modelos y este valor no tiene influencia en el rendimiento de los mismos."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.drop(['ever_married'], axis=1, inplace=True)\n","df.info()"]},{"cell_type":"markdown","metadata":{},"source":["#### Observaremos la distribución de estado de fumador en base a la edad y como esta influye a la hora de padecer un ACV"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w3D-5lK3Pt1y","outputId":"600b7d29-690e-4650-a185-fbb5dcef99fe"},"outputs":[],"source":["df_smoking = df[(df['smoking_status']) != 'Unknown']\n","df_smoking2 = df.copy()\n","df_smoking2['stroke'].replace(\n","                to_replace=[0, 1], \n","                value=[\"No\",\"Yes\"], \n","                inplace=True)\n","ax = sns.catplot(data=df_smoking2, kind='violin', x='smoking_status', y='age',   hue='stroke', split=True)\n","ax.set(xlabel='Smoking Status', ylabel='Edad', title='Categorización de ACV por edad y estado de fumador.')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["#### A continuación realizaremos gráficos de boxplot para todas las columnas, con el fin de observar con mayor detalle la distribución de valores junto a la presencia (o no) de outliers."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["variables = ['bmi', 'avg_glucose_level', 'age']\n","\n","fig, axes = plt.subplots(1, len(variables), figsize=(10,5))\n","\n","for ax, variable in zip(axes, variables):\n","    ax = sns.boxplot( y=variable, data=df, ax=ax)\n","plt.tight_layout()\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["#### En los gráficos de boxplot se pueden observar una gran presencia de outliers (valores atípicos), estos se mantendrán en el dataset ya que en este caso en particular, no presenta un problema, siendo que son valores válidos y representan la gran cantidad de datos. Eliminarlos reduciría la utilidad del dataset de forma drástica"]},{"cell_type":"markdown","metadata":{},"source":["#### Aplicación de modelos de ML"]},{"cell_type":"markdown","metadata":{},"source":["#### Una vez realizado los diferentes tipos de análisis y limpieza de datos necesaria, es momento de aplicar algoritmos."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Creamos un data dummie para obtener las variables categóricas como booleanas (es decir 0,1)\n","df_dummy = pd.get_dummies(df, drop_first=True)\n","df_dummy = df_dummy.drop('id', axis=1)\n","df_dummy    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Separamos los datos de entrada de la salida\n","X = df_dummy.drop('stroke', axis=1) #Elimino de mi dataset la variable a predecir\n","y = df_dummy.stroke #Defino el Target"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Seteamos los valores para separar el testeo del train, un 20% para testear y 80% para entrenamiento.\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42) "]},{"cell_type":"markdown","metadata":{},"source":["##### Como primer algoritmo, nos decantaremos por la regresión logística binaria en base a su naturaleza de predecir la probabilidad de una variable categórica. (En este caso, 1 sí es propenso a tener un ACV; 0 si no)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["logreg = LogisticRegression()\n","logreg.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_pred = logreg.predict(X_test)\n","print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["confusion_matrix = confusion_matrix(y_test, y_pred)\n","print(confusion_matrix)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(classification_report(y_test, y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\n","fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\n","plt.figure()\n","plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n","plt.plot([0, 1], [0, 1],'r--')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver operating characteristic')\n","plt.legend(loc=\"lower right\")\n","plt.savefig('Log_ROC')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["#### Para continuar, el segundo algoritmo que utilizaremos sera el DecisionTreeClassifier (Arbol de decisión)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tree = DecisionTreeClassifier(random_state = 42, class_weight=\"balanced\") #Creamos el modelo"]},{"cell_type":"markdown","metadata":{},"source":["#### Se agregó el hiperparámetro class_weight=\"balanced\" para ayudar al algoritmo DecisionTree a trabajar con un set de datos desbalanceado."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["param_dict = {\n","    \"criterion\":['gini','entropy'],\n","    \"max_depth\":range(1,10),\n","    \"min_samples_split\":range(1,10),\n","    \"min_samples_leaf\":range(1,5)\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["grid = GridSearchCV(tree,\n","                    param_grid=param_dict,\n","                    cv=3,\n","                    verbose=1,\n","                    n_jobs=1)\n","grid.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["grid.best_params_"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["grid.best_estimator_"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["grid.best_score_"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_train_pred = tree.predict(X_train) #Prediccion en Train\n","y_test_pred = tree.predict(X_test) #Prediccion en Test"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class_probabilities = grid.predict_proba(X_test)\n","preds = class_probabilities[:, 1]\n","\n","fpr, tpr, threshold = roc_curve(y_test, preds)\n","roc_auc = auc(fpr, tpr)\n","\n","# AUC\n","print(f\"AUC for our classifier is: {roc_auc}\")\n","\n","# Gráfica de la Curva ROC\n","plt.title('Receiver Operating Characteristic')\n","plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n","plt.legend(loc = 'lower right')\n","plt.plot([0, 1], [0, 1],'r--')\n","plt.xlim([0, 1])\n","plt.ylim([0, 1])\n","plt.ylabel('True Positive Rate')\n","plt.xlabel('False Positive Rate')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(classification_report(y_test, y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Matriz de confusión para evaluar el desempeño del algoritmo\n","print(confusion_matrix(y_test, y_test_pred))"]},{"cell_type":"markdown","metadata":{},"source":["#### Además del algoritmo DecisionTree, aplicaremos KNeighborsClassifier y Random Forest para ver su efectividad."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Creamos nuestro objeto KNN\n","knn = KNeighborsClassifier()"]},{"cell_type":"markdown","metadata":{},"source":["#### Recurriremos al uso de GridSearchCV para obtener la mejor configuración de hiper parámetros."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Definicion de Hyperparámetros\n","param_grid = {'n_neighbors':np.arange(1, 10),\n","              'weights': ['uniform', 'distance'], \n","              'leaf_size':[1,3,5,7,10],\n","              'algorithm':['auto', 'kd_tree']}\n","\n","#Utilizamos la grilla definida anteriormente...\n","model = GridSearchCV(knn, param_grid=param_grid, cv=3)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Mejores parametros: \"+str(model.best_params_))\n","print(\"Mejor Score: \"+str(model.best_score_)+'\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["scores = pd.DataFrame(model.cv_results_)\n","scores"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["prediction = model.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Accuracy\n","print('Exactitud:', accuracy_score(y_test, prediction))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class_probabilities = model.predict_proba(X_test)\n","preds = class_probabilities[:, 1]\n","\n","fpr, tpr, threshold = roc_curve(y_test, preds)\n","roc_auc = auc(fpr, tpr)\n","\n","# AUC\n","print(f\"AUC for our classifier is: {roc_auc}\")\n","\n","# Gráfica de la Curva ROC\n","plt.title('Receiver Operating Characteristic')\n","plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n","plt.legend(loc = 'lower right')\n","plt.plot([0, 1], [0, 1],'r--')\n","plt.xlim([0, 1])\n","plt.ylim([0, 1])\n","plt.ylabel('True Positive Rate')\n","plt.xlabel('False Positive Rate')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(classification_report(y_test, y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Acudiremos a una matriz de confusión para obtener los resultados del modelo\n","print(confusion_matrix(y_test, y_test_pred))\n","\n","#Ploteamos la Matriz\n","\n","plot_confusion_matrix(model, X_test, y_test)\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Creamos un random forest!\n","rfc=RandomForestClassifier(random_state=42, class_weight=\"balanced\")\n","param_grid = { \n","    'n_estimators': [200, 500],\n","    'max_features': ['auto', 'sqrt', 'log2'],\n","    'max_depth' : [4,5,6,7,8],\n","    'criterion' :['gini', 'entropy']\n","}\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 3)\n","CV_rfc.fit(X_train, y_train)    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["CV_rfc.best_params_"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["rfc1=RandomForestClassifier(random_state=42, max_features='auto', n_estimators= 200, max_depth=2, criterion='gini')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["rfc1.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pred=rfc1.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_test_pred = model.predict(X_test) #Prediccion en Test"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class_probabilities = rfc1.predict_proba(X_test)\n","preds = class_probabilities[:, 1]\n","\n","fpr, tpr, threshold = roc_curve(y_test, preds)\n","roc_auc = auc(fpr, tpr)\n","\n","# AUC\n","print(f\"AUC for our classifier is: {roc_auc}\")\n","\n","# Gráfica de la Curva ROC\n","plt.title('Receiver Operating Characteristic')\n","plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n","plt.legend(loc = 'lower right')\n","plt.plot([0, 1], [0, 1],'r--')\n","plt.xlim([0, 1])\n","plt.ylim([0, 1])\n","plt.ylabel('True Positive Rate')\n","plt.xlabel('False Positive Rate')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(classification_report(y_test, y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Matriz de confusión para evaluar el desempeño del algoritmo RANDOM FOREST\n","print(confusion_matrix(y_test, y_test_pred))\n","plot_confusion_matrix(rfc1, X_test, y_test)\n","plt.show()"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"leanbruzzo_1raentrega.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.10.7 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.7"},"vscode":{"interpreter":{"hash":"8dfb18b20b1c5be31ebdb32c9f5f048ff20716d499c9b4ee56ead56f42de095d"}}},"nbformat":4,"nbformat_minor":0}
